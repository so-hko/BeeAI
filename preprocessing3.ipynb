{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGsXSxh8L190g9Ev2gmDn3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/so-hko/BeeAI/blob/master/preprocessing3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh-S-pHoNQFd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "\n",
        "data = pd.read_csv(\"/content/Falults.csv\")\n",
        "is_Pastry = data['Pastry'] == 1\n",
        "Pastry = data[is_Pastry]\n",
        "Pastry80, Pastry20 = train_test_split(Pastry, test_size=0.2, shuffle=True, random_state=1004)\n",
        "\n",
        "is_Z_Scratch = data['Z_Scratch'] == 1\n",
        "Z_Scratch = data[is_Z_Scratch]\n",
        "Z_Scratch80, Z_Scratch20 = train_test_split(Z_Scratch, test_size=0.2, shuffle=True, random_state=1004)\n",
        "\n",
        "is_K_Scratch = data['K_Scatch'] == 1\n",
        "K_Scratch = data[is_K_Scratch]\n",
        "K_Scratch80, K_Scratch20 = train_test_split(K_Scratch, test_size=0.2, shuffle=True, random_state=1004)\n",
        "\n",
        "is_Stains = data['Stains'] == 1\n",
        "Stains = data[is_Stains]\n",
        "Stains80, Stains20 = train_test_split(Stains, test_size=0.2, shuffle=True, random_state=1004)\n",
        "\n",
        "is_Dirtiness = data['Dirtiness'] == 1\n",
        "Dirtiness = data[is_Dirtiness]\n",
        "Dirtiness80, Dirtiness20 = train_test_split(Dirtiness, test_size=0.2, shuffle=True, random_state=1004)\n",
        "\n",
        "is_Bumps = data['Bumps'] == 1\n",
        "Bumps = data[is_Bumps]\n",
        "Bumps80, Bumps20 = train_test_split(Bumps, test_size=0.2, shuffle=True, random_state=1004)\n",
        "\n",
        "is_Other_Faults = data['Other_Faults'] == 1\n",
        "Other_Faults = data[is_Other_Faults]\n",
        "Other_Faults80, Other_Faults20 = train_test_split(Other_Faults, test_size=0.2, shuffle=True, random_state=1004)\n",
        "\n",
        "train80 = pd.concat([Pastry80,K_Scratch80, Z_Scratch80, Stains80, Dirtiness80, Bumps80, Other_Faults80])\n",
        "train80_shuffled=sklearn.utils.shuffle(train80)\n",
        "row = len(train80_shuffled)-1\n",
        "\n",
        "for i in range(row+1):\n",
        "  train80_shuffled = train80_shuffled.append(train80_shuffled.loc[[i]], ignore_index = True)\n",
        "  row = row + 1\n",
        "  random2 = randint(0,26)\n",
        "  train80_shuffled.loc[row:row,[train80_shuffled.columns[random2]]] = np.nan\n",
        "\n",
        "data_train_shuffled=sklearn.utils.shuffle(train80_shuffled)\n",
        "data_train_shuffled.to_csv('./data_train.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4do1ax2BQ9VR",
        "outputId": "4179d53d-8ebd-4301-a5bb-c487b4d1bc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "train20 = pd.concat([Pastry20,K_Scratch20, Z_Scratch20, Stains20, Dirtiness20, Bumps20, Other_Faults20])\n",
        "train20_shuffled=sklearn.utils.shuffle(train20)\n",
        "train20_shuffled.to_csv('./train20_shuffled.csv',index=False)\n",
        "train20_shuffled = pd.read_csv('./train20_shuffled.csv')\n",
        "print(train20_shuffled)\n",
        "\n",
        "row = len(train20_shuffled)-1\n",
        "print(row)\n",
        "for i in range(row+1):\n",
        "  #random1 = randint(1,1941)\n",
        "  #print(data.loc[[random1]])\n",
        "  train20_shuffled = train20_shuffled.append(train20_shuffled.loc[[i]], ignore_index = True)\n",
        "  row = row + 1\n",
        "  random2 = randint(0,26)\n",
        "  train20_shuffled.loc[row:row,[train20_shuffled.columns[random2]]] = np.nan\n",
        "\n",
        "data_test_shuffled=sklearn.utils.shuffle(train20_shuffled)\n",
        "data_test_shuffled.to_csv('./data_test.csv')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     X_Minimum  X_Maximum  Y_Minimum  ...  Dirtiness  Bumps  Other_Faults\n",
            "0           39        212    2730163  ...          0      0             0\n",
            "1          604        621     850713  ...          0      1             0\n",
            "2         1292       1372    1506506  ...          0      0             1\n",
            "3          621        632    2036193  ...          1      0             0\n",
            "4          953        962    3681237  ...          0      1             0\n",
            "..         ...        ...        ...  ...        ...    ...           ...\n",
            "386         49         71    1427809  ...          0      0             0\n",
            "387       1251       1258     660048  ...          0      0             1\n",
            "388       1543       1562    1312943  ...          0      0             1\n",
            "389        284        357    2286293  ...          0      0             1\n",
            "390         34         40     914648  ...          0      0             0\n",
            "\n",
            "[391 rows x 34 columns]\n",
            "390\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}